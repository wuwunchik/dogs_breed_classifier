import streamlit as st
import tensorflow as tf
import numpy as np
from PIL import Image
import wikipedia
from breed_translation import breed_translation

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
@st.cache_resource
def load_model():
    return tf.keras.models.load_model("dogs_model.keras")

# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ –ø–æ—Ä–æ–¥
@st.cache_data
def load_class_names():
    with open("class_names.txt", "r") as f:
        return [line.strip() for line in f.readlines()]

# –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
def preprocess_image(image, target_size=(224, 224)):
    image = image.resize(target_size)
    img_array = tf.keras.preprocessing.image.img_to_array(image)
    img_array = tf.expand_dims(img_array, axis=0)
    return tf.keras.applications.efficientnet.preprocess_input(img_array)

# –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –í–∏–∫–∏–ø–µ–¥–∏–∏
def get_wiki_description(breed_name):
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–≤–æ–¥ –ø–æ—Ä–æ–¥—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–∞ –í–∏–∫–∏–ø–µ–¥–∏–∏
        breed_ru = breed_translation.get(breed_name, breed_name)  # –ü–æ–ª—É—á–∞–µ–º —Ä—É—Å—Å–∫–∏–π –ø–µ—Ä–µ–≤–æ–¥ –ø–æ—Ä–æ–¥—ã
        wiki_page = wikipedia.page(breed_ru, auto_suggest=False)
        return wiki_page.summary[:500] + "..."  # –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø–æ—Ä–æ–¥—ã
    except wikipedia.exceptions.DisambiguationError as e:
        return f"–ï—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –¥–ª—è {breed_name}. –ù–∞–ø—Ä–∏–º–µ—Ä: {', '.join(e.options[:5])}."
    except wikipedia.exceptions.HTTPError as e:
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –í–∏–∫–∏–ø–µ–¥–∏–∏."
    except Exception as e:
        return str(e)

# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å
st.title("üê∂ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Ä–æ–¥—ã —Å–æ–±–∞–∫–∏ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é")

uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ–±–∞–∫–∏", type=["jpg", "jpeg", "png"])

if uploaded_file:
    image = Image.open(uploaded_file).convert("RGB")
    st.image(image, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_container_width=True)

    model = load_model()
    class_names = load_class_names()

    img_array = preprocess_image(image)
    prediction = model.predict(img_array)[0]
    predicted_idx = np.argmax(prediction)
    confidence = prediction[predicted_idx]
    predicted_breed = class_names[predicted_idx]

    # –ü–æ–ª—É—á–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –ø–æ—Ä–æ–¥—ã —Å –í–∏–∫–∏–ø–µ–¥–∏–∏
    breed_description = get_wiki_description(predicted_breed)

    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    st.markdown(f"### üêï –ü–æ—Ä–æ–¥–∞: **{breed_translation.get(predicted_breed, predicted_breed)}**")
    st.markdown(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: **{confidence:.2%}**")
    st.markdown(f"**–û–ø–∏—Å–∞–Ω–∏–µ –ø–æ—Ä–æ–¥—ã**: {breed_description}")
